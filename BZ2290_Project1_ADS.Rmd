---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---
```{r}
#Before we start to analysis the inaugration speech given by each president, we have to read in and preprecess our data to ease our analysis that will be carried out later.
```

```{r}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(RCurl)
library(dplyr)
library(ggplot2)
##PREPRCESSIONING OF THE DATA##

folder.path="D:/Columbia University/Spring2017-Applied Data Science/Project_1_Bz2290/Spr2017-Proj1-bz2290/data/InauguralSpeeches"
speeches=list.files(path = folder.path, pattern = "*.txt")
prez.out=substr(speeches, 6, nchar(speeches)-4)
length.speeches=rep(NA, length(speeches))
ff.all<-Corpus(DirSource(folder.path))
#REMOVE WHITE SPACE FROM CORPUS
ff.all<-tm_map(ff.all, stripWhitespace)
#TRANSFORM LETTERS TO LOWER CASE TO WAS OUR ANALYSIS
ff.all<-tm_map(ff.all, content_transformer(tolower))
#REMOVE COMMON STOPWORDS IN ENGLISH
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
#REMOVE EMPTY CHARATERS
ff.all<-tm_map(ff.all, removeWords, character(0))
#REMOVE PUNCTIONS
ff.all<-tm_map(ff.all, removePunctuation)
#REMOVE NUMBERS
ff.all = tm_map(ff.all,removeNumbers)

#TURN INTO A DOCUMENT MATRIX
dtm<-DocumentTermMatrix(ff.all)
#REMOVE SPASRE WORD
#dtms = removeSparseTerms(dtm,0.1)
#WRITE is into a CSV
write.csv(as.matrix(dtm),file="dtm.csv")

#tdm.tidy=tidy(tdm.all)
#tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
```

```{r}
###Sentiment analysis###

table = read.csv("dtm.csv",header=TRUE)
table$Presdient = gsub("inaug|.txt","",table$X)
#dates = read.table("InauguationDatesEdit.txt",header = TRUE)
#dates$FIRST = gsub("[0-9]+[/][0-9]+[/]","",dates$FIRST)
#dates$SECOND = gsub("[0-9]+[/][0-9]+[/]","",dates$SECOND)
#dates$THIRD = gsub("[0-9]+[/][0-9]+[/]","",dates$THIRD)
#dates$FOURTH = gsub("[0-9]+[/][0-9]+[/]","",dates$FOURTH)
#dates=dates[order(dates$PRESIDENT),]
#for(i in 1:45)
{
#  if(is.na(dates[i,3]))
  {
#     dates$PRESIDENT[i] = paste(dates$PRESIDENT,"-1",sep="")
  }
#  else
  {
#    rbind(dates,)
  }
}
positives= readLines("positive-words.txt")
negatives = readLines("negative-words.txt")
#Sentiment Score Function#

    score.sentiment =  function(lines, pos.words, neg.words) {
        # split into words. str_split is in the stringr package
        words = unlist(strsplit(lines, '\\s+'))
        # compare our words to the dictionaries of positive & negative terms
        pos.matches = match(words, pos.words)
        neg.matches = match(words, neg.words)
        # match() returns the position of the matched term or NA
        # we just want a TRUE/FALSE:
        pos.matches = !is.na(pos.matches)
        neg.matches = !is.na(neg.matches)
        # and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
        score = sum(pos.matches) - sum(neg.matches)
        return(score)
      }
    senti_scores = c()
for(i in 1 : dim(table)[1])
{
  lines = unlist(strsplit(ff.all[[i]]$content,"\\s+"))
  senti_scores[i] = score.sentiment(lines,positives,negatives)
}
table$sentiscores=senti_scores

#Plot the sentiment scores against President
plot.data.senti = as.data.frame(table[,9352:9353])
ggplot(plot.data.senti,aes(x=factor(plot.data.senti$Presdient),y=plot.data.senti$sentiscores))+
  geom_point()+
  labs(title="Snetiment Scores for Presidential Inaugration Speech",y="Sentiment Scores",x = "Years")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


